{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-29T08:16:07.221069Z",
     "iopub.status.busy": "2023-11-29T08:16:07.220964Z",
     "iopub.status.idle": "2023-11-29T08:16:08.426754Z",
     "shell.execute_reply": "2023-11-29T08:16:08.426141Z",
     "shell.execute_reply.started": "2023-11-29T08:16:07.221059Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "from warnings import simplefilter\n",
    "import lightgbm as lgb\n",
    "import catboost as cbt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:16:08.427513Z",
     "iopub.status.busy": "2023-11-29T08:16:08.427398Z",
     "iopub.status.idle": "2023-11-29T08:16:08.431196Z",
     "shell.execute_reply": "2023-11-29T08:16:08.430672Z",
     "shell.execute_reply.started": "2023-11-29T08:16:08.427502Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \"\"\"\n",
    "    Configuration class for parameters and CV strategy for tuning and training\n",
    "    Please use caps lock capital letters while filling in parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Data preparation\n",
    "    version_nb         = 3\n",
    "    is_gpu             = True\n",
    "    # device             = torch.device('cuda' if torch.cuda.is_available() and gpu_switch else 'cpu')\n",
    "    state              = 42\n",
    "    num_workers        = 4\n",
    "\n",
    "    # BEFORE SUBMIT, CHECK SETTINGS\n",
    "    is_test_mode       = False\n",
    "    test_mode_frac     = 10\n",
    "    is_offline         = True\n",
    "    testing_days       = 2\n",
    "\n",
    "    target             = 'target'    \n",
    "    path               = '/kaggle/input/optiver-trading-at-the-close'\n",
    "    train_path         = f'{path}/train.csv'\n",
    "    test_path          = f'{path}/example_test_files/test.csv'\n",
    "    model_path         = f'' if not is_offline else f'{path}/'\n",
    "    \n",
    "    TRAINING           = True\n",
    "    INFERENCE          = True\n",
    "    TUNING             = False\n",
    "    \n",
    "    methods            = ['LGBM',]\n",
    "    # methods            = ['CBT']\n",
    "\n",
    "    plt_path = f'fig/turning'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Data Loading and Preprocessing \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:16:08.431823Z",
     "iopub.status.busy": "2023-11-29T08:16:08.431716Z",
     "iopub.status.idle": "2023-11-29T08:16:14.133064Z",
     "shell.execute_reply": "2023-11-29T08:16:14.132419Z",
     "shell.execute_reply.started": "2023-11-29T08:16:08.431814Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5237892, 17)\n"
     ]
    }
   ],
   "source": [
    "# 📂 Read the dataset from a CSV file using Pandas\n",
    "df = pd.read_csv(CFG.train_path)\n",
    "if CFG.is_test_mode:\n",
    "    df = df[df['stock_id'] < 10]\n",
    "\n",
    "# 🧹 Remove rows with missing values in the \"target\" column\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "\n",
    "# 🔁 Reset the index of the DataFrame and apply the changes in place\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 📏 Get the shape of the DataFrame (number of rows and columns)\n",
    "df_shape = df.shape\n",
    "print(df_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Memory Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:16:14.133829Z",
     "iopub.status.busy": "2023-11-29T08:16:14.133715Z",
     "iopub.status.idle": "2023-11-29T08:16:14.139607Z",
     "shell.execute_reply": "2023-11-29T08:16:14.139177Z",
     "shell.execute_reply.started": "2023-11-29T08:16:14.133819Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=0):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "               \n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "    if verbose:\n",
    "        logger.info(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n",
    "        end_mem = df.memory_usage().sum() / 1024**2\n",
    "        logger.info(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n",
    "        decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "        logger.info(f\"Decreased by {decrease:.2f}%\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    " # Parallel Triplet Imbalance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:16:14.140246Z",
     "iopub.status.busy": "2023-11-29T08:16:14.140138Z",
     "iopub.status.idle": "2023-11-29T08:16:14.380573Z",
     "shell.execute_reply": "2023-11-29T08:16:14.379966Z",
     "shell.execute_reply.started": "2023-11-29T08:16:14.140236Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True)\n",
    "def compute_triplet_imbalance(df_values, comb_indices):\n",
    "    num_rows = df_values.shape[0]\n",
    "    num_combinations = len(comb_indices)\n",
    "    imbalance_features = np.empty((num_rows, num_combinations))\n",
    "    for i in prange(num_combinations):\n",
    "        a, b, c = comb_indices[i]\n",
    "        for j in range(num_rows):\n",
    "            max_val = max(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            min_val = min(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            mid_val = df_values[j, a] + df_values[j, b] + df_values[j, c] - min_val - max_val\n",
    "            \n",
    "            if mid_val == min_val:\n",
    "                imbalance_features[j, i] = np.nan\n",
    "            else:\n",
    "                imbalance_features[j, i] = (max_val - mid_val) / (mid_val - min_val)\n",
    "\n",
    "    return imbalance_features\n",
    "\n",
    "def calculate_triplet_imbalance_numba(price, df):\n",
    "    df_values = df[price].values\n",
    "    comb_indices = [(price.index(a), price.index(b), price.index(c)) for a, b, c in combinations(price, 3)]\n",
    "    features_array = compute_triplet_imbalance(df_values, comb_indices)\n",
    "    columns = [f\"{a}_{b}_{c}_imb2\" for a, b, c in combinations(price, 3)]\n",
    "    features = pd.DataFrame(features_array, columns=columns)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighbors Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:16:14.383332Z",
     "iopub.status.busy": "2023-11-29T08:16:14.383113Z",
     "iopub.status.idle": "2023-11-29T08:16:14.439504Z",
     "shell.execute_reply": "2023-11-29T08:16:14.438904Z",
     "shell.execute_reply.started": "2023-11-29T08:16:14.383311Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "N_NEIGHBORS_MAX = 80 if not CFG.is_test_mode else 5\n",
    "\n",
    "class Neighbors:\n",
    "    def __init__(self, \n",
    "                 name: str, \n",
    "                 pivot: pd.DataFrame, \n",
    "                 p: float, \n",
    "                 metric: str = 'minkowski', \n",
    "                 metric_params: Optional[Dict] = None, \n",
    "                 exclude_self: bool = False):\n",
    "        self.name = name\n",
    "        self.exclude_self = exclude_self\n",
    "        self.p = p\n",
    "        self.metric = metric\n",
    "        \n",
    "        if metric == 'random':\n",
    "            n_queries = len(pivot)\n",
    "            self.neighbors = np.random.randint(n_queries, size=(n_queries, N_NEIGHBORS_MAX))\n",
    "        else:\n",
    "            nn = NearestNeighbors(\n",
    "                n_neighbors=N_NEIGHBORS_MAX, \n",
    "                p=p, \n",
    "                metric=metric, \n",
    "                metric_params=metric_params\n",
    "            )\n",
    "            nn.fit(pivot)\n",
    "            _, self.neighbors = nn.kneighbors(pivot, return_distance=True)\n",
    "\n",
    "        self.columns = self.index = self.feature_values = self.feature_col = None\n",
    "\n",
    "    def rearrange_feature_values(self, df: pd.DataFrame, feature_col: str) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def make_nn_feature(self, n=5, agg=np.mean) -> pd.DataFrame:\n",
    "        assert self.feature_values is not None, \"should call rearrange_feature_values beforehand\"\n",
    "\n",
    "        start = 1 if self.exclude_self else 0\n",
    "\n",
    "        pivot_aggs = pd.DataFrame(\n",
    "            agg(self.feature_values[start:n,:,:], axis=0), \n",
    "            columns=self.columns, \n",
    "            index=self.index\n",
    "        )\n",
    "\n",
    "        dst = pivot_aggs.unstack().reset_index()\n",
    "        dst.columns = ['stock_id', 'time_id', f'{self.feature_col}_nn{n}_{self.name}_{agg.__name__}']\n",
    "        return dst\n",
    "\n",
    "\n",
    "class TimeIdNeighbors(Neighbors):\n",
    "    def rearrange_feature_values(self, df: pd.DataFrame, feature_col: str) -> None:\n",
    "        feature_pivot = df.pivot('time_id', 'stock_id', feature_col)\n",
    "        feature_pivot = feature_pivot.fillna(feature_pivot.mean())\n",
    "        feature_pivot.head()\n",
    "\n",
    "        feature_values = np.zeros((N_NEIGHBORS_MAX, *feature_pivot.shape))\n",
    "\n",
    "        for i in range(N_NEIGHBORS_MAX):\n",
    "            feature_values[i, :, :] += feature_pivot.values[self.neighbors[:, i], :]\n",
    "\n",
    "        self.columns = list(feature_pivot.columns)\n",
    "        self.index = list(feature_pivot.index)\n",
    "        self.feature_values = feature_values\n",
    "        self.feature_col = feature_col\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"time-id NN (name={self.name}, metric={self.metric}, p={self.p})\"\n",
    "\n",
    "\n",
    "class StockIdNeighbors(Neighbors):\n",
    "    def rearrange_feature_values(self, df: pd.DataFrame, feature_col: str) -> None:\n",
    "        \"\"\"stock-id based nearest neighbor features\"\"\"\n",
    "        feature_pivot = df.pivot(index='time_id', columns='stock_id', values=feature_col)\n",
    "        feature_pivot = feature_pivot.fillna(feature_pivot.mean())\n",
    "\n",
    "        feature_values = np.zeros((N_NEIGHBORS_MAX, *feature_pivot.shape))\n",
    "\n",
    "        for i in range(N_NEIGHBORS_MAX):\n",
    "            feature_values[i, :, :] += feature_pivot.values[:, self.neighbors[:, i]]\n",
    "\n",
    "        self.columns = list(feature_pivot.columns)\n",
    "        self.index = list(feature_pivot.index)\n",
    "        self.feature_values = feature_values\n",
    "        self.feature_col = feature_col\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"stock-id NN (name={self.name}, metric={self.metric}, p={self.p})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:16:14.440204Z",
     "iopub.status.busy": "2023-11-29T08:16:14.440090Z",
     "iopub.status.idle": "2023-11-29T08:16:14.442551Z",
     "shell.execute_reply": "2023-11-29T08:16:14.442114Z",
     "shell.execute_reply.started": "2023-11-29T08:16:14.440194Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# pivot = df_train.pivot(index='time_id', columns='stock_id', values='target')\n",
    "# pivot = pivot.fillna(pivot.mean())\n",
    "# pivot = pd.DataFrame(minmax_scale(pivot))\n",
    "\n",
    "# stock_id_neighbors = []\n",
    "# stock_id_neighbors.append(StockIdNeighbors(\n",
    "#     name='stock_price_l1', \n",
    "#     pivot=minmax_scale(pivot.T), \n",
    "#     p=1, # manhattan_distance (l1)\n",
    "#     exclude_self=True\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:16:14.449344Z",
     "iopub.status.busy": "2023-11-29T08:16:14.449234Z",
     "iopub.status.idle": "2023-11-29T08:16:14.451601Z",
     "shell.execute_reply": "2023-11-29T08:16:14.451161Z",
     "shell.execute_reply.started": "2023-11-29T08:16:14.449335Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# stock_ids = np.array(sorted(df_train['stock_id'].unique()))\n",
    "# # for neighbor in stock_id_neighbors:\n",
    "# print(neighbor)\n",
    "# display(\n",
    "#     pd.DataFrame(\n",
    "#         stock_ids[stock_id_neighbors[0].neighbors[:,:5]], \n",
    "#         index=pd.Index(stock_ids, name='stock_id'), \n",
    "#         columns=[f'top_{i+1}' for i in range(5)]\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:16:14.452244Z",
     "iopub.status.busy": "2023-11-29T08:16:14.452134Z",
     "iopub.status.idle": "2023-11-29T08:16:14.458631Z",
     "shell.execute_reply": "2023-11-29T08:16:14.458206Z",
     "shell.execute_reply.started": "2023-11-29T08:16:14.452234Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_nearest_neighbor_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df2 = df.copy()\n",
    "    feature_cols_stock = {\n",
    "        'imbalance_size': [np.mean, np.min, np.max, np.std],\n",
    "        'reference_price': [np.mean, np.min, np.max, np.std],\n",
    "        'matched_size': [np.mean],\n",
    "        'far_price': [np.mean],\n",
    "        'near_price': [np.mean],\n",
    "        'bid_price': [np.mean],\n",
    "        'ask_price': [np.mean],\n",
    "        'wap': [np.mean],\n",
    "    }\n",
    "\n",
    "    pivot = df_train.pivot(index='time_id', columns='stock_id', values='target')\n",
    "    pivot = pivot.fillna(pivot.mean())\n",
    "    pivot = pd.DataFrame(minmax_scale(pivot))\n",
    "    \n",
    "    stock_id_neighbors = []\n",
    "    stock_id_neighbors.append(StockIdNeighbors(\n",
    "        name='stock_price_l1', \n",
    "        pivot=minmax_scale(pivot.T), \n",
    "        p=1, # manhattan_distance (l1)\n",
    "        exclude_self=True\n",
    "    ))\n",
    "\n",
    "    stock_ids = np.array(sorted(df_train['stock_id'].unique()))\n",
    "    # for neighbor in stock_id_neighbors:\n",
    "    # print(neighbor)\n",
    "    display(\n",
    "        pd.DataFrame(\n",
    "            stock_ids[stock_id_neighbors[0].neighbors[:,:5]], \n",
    "            index=pd.Index(stock_ids, name='stock_id'), \n",
    "            columns=[f'top_{i+1}' for i in range(5)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    stock_id_neighbor_sizes = [10, 20, 40]\n",
    "    \n",
    "    ndf: Optional[pd.DataFrame] = None\n",
    "    \n",
    "    def _add_ndf(ndf: Optional[pd.DataFrame], dst: pd.DataFrame) -> pd.DataFrame:\n",
    "        if ndf is None:\n",
    "            return dst\n",
    "        else:\n",
    "            ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
    "            return ndf\n",
    "    \n",
    "    # neighbor stock_id\n",
    "    for feature_col in feature_cols_stock.keys():\n",
    "        try:\n",
    "            if feature_col not in df2.columns:\n",
    "                print(f\"column {feature_col} is skipped\")\n",
    "                continue\n",
    "        \n",
    "            if not stock_id_neighbors:\n",
    "                continue\n",
    "        \n",
    "            for nn in stock_id_neighbors:\n",
    "                nn.rearrange_feature_values(df2, feature_col)\n",
    "        \n",
    "            for agg in feature_cols_stock[feature_col]:\n",
    "                for n in stock_id_neighbor_sizes:\n",
    "                    try:\n",
    "                        for nn in stock_id_neighbors:\n",
    "                            dst = nn.make_nn_feature(n, agg)\n",
    "                            ndf = _add_ndf(ndf, dst)\n",
    "                    except Exception as e:\n",
    "                        print('stock-id nn', e)\n",
    "                        pass\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    if ndf is not None:\n",
    "        df2 = pd.merge(df2, ndf, on=['time_id', 'stock_id'], how='left')\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Feature Generation Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:16:14.459276Z",
     "iopub.status.busy": "2023-11-29T08:16:14.459168Z",
     "iopub.status.idle": "2023-11-29T08:16:14.468694Z",
     "shell.execute_reply": "2023-11-29T08:16:14.468239Z",
     "shell.execute_reply.started": "2023-11-29T08:16:14.459267Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def imbalance_features(df):\n",
    "    # Define lists of price and size-related column names\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n",
    "    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n",
    "    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "    df[\"matched_imbalance\"] = df.eval(\"(imbalance_size-matched_size)/(matched_size+imbalance_size)\")\n",
    "    df[\"size_imbalance\"] = df.eval(\"bid_size / ask_size\")\n",
    "    df[\"size_imbalance_bid\"] = df.eval(\"imbalance_size / bid_size\")\n",
    "    df[\"size_imbalance_ask\"] = df.eval(\"imbalance_size / ask_size\")\n",
    "    df[\"matched_size_bid_ask\"] = df.eval(\"matched_size / (bid_size+ask_size)\")\n",
    "\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n",
    "\n",
    "    for c in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "   \n",
    "    df[\"imbalance_momentum\"] = df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / df['matched_size']\n",
    "    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"spread_intensity\"] = df.groupby(['stock_id'])['price_spread'].diff()\n",
    "    df['price_pressure'] = df['imbalance_size'] * (df['ask_price'] - df['bid_price'])\n",
    "    df['market_urgency'] = df['price_spread'] * df['liquidity_imbalance']\n",
    "    df['depth_pressure'] = (df['ask_size'] - df['bid_size']) * (df['far_price'] - df['near_price'])\n",
    "    \n",
    "    # Calculate various statistical aggregation features\n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "        \n",
    "\n",
    "    for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            df[f\"{col}_shift_{window}\"] = df.groupby('stock_id')[col].shift(window)\n",
    "            df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window)\n",
    "\n",
    "            if window == 1:\n",
    "                continue\n",
    "\n",
    "            date_ids = df['date_id'].unique()\n",
    "            agg_func = ['mean', 'sum']\n",
    "            moving_li = []\n",
    "            \n",
    "            for date in date_ids:\n",
    "                moving_li.append(\n",
    "                    df[df['date_id'] == date].groupby('stock_id')[col].rolling(window).agg(agg_func).reset_index().set_index('level_1')[agg_func]\n",
    "                )\n",
    "            df[[f'{col}_moving_average_{window}', f'{col}_moving_sum_{window}']] = pd.concat(moving_li)[agg_func]\n",
    "    \n",
    "    # Calculate diff features for specific columns\n",
    "    for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size', 'market_urgency', 'imbalance_momentum', 'size_imbalance']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window)\n",
    "\n",
    "    # --- add\n",
    "    # Calculate diff prices\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f'{c[0]}_{c[1]}_diff'] = df.eval(f'({c[0]} - {c[1]})')\n",
    "\n",
    "    return df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "def other_features(df):\n",
    "    df[\"dow\"] = df[\"date_id\"] % 5  # Day of the week\n",
    "    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  \n",
    "    df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  \n",
    "    for key, value in global_stock_id_feats.items():\n",
    "        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
    "\n",
    "    for key, value in global_weight_feats.items():\n",
    "        df[f\"global_{key}\"] = df[\"weight_label\"].map(value.to_dict())\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_all_features(df, feature_name=None):\n",
    "    # Select relevant columns for feature generation\n",
    "    cols = [c for c in df.columns if c not in [\"row_id\", \"time_id\", \"target\"]]\n",
    "    df = df[cols]\n",
    "    \n",
    "    # Generate imbalance features\n",
    "    df = imbalance_features(df)\n",
    "    df = other_features(df)\n",
    "    df = make_nearest_neighbor_feature(df)\n",
    "    gc.collect()  \n",
    "\n",
    "    if not feature_name:\n",
    "        feature_name = [i for i in df.columns if i not in [\"row_id\", \"target\", \"time_id\", \"date_id\", 'ask_price_bid_price_diff']]\n",
    "    \n",
    "    return df[feature_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:16:14.481906Z",
     "iopub.status.busy": "2023-11-29T08:16:14.481801Z",
     "iopub.status.idle": "2023-11-29T08:16:14.489506Z",
     "shell.execute_reply": "2023-11-29T08:16:14.489049Z",
     "shell.execute_reply.started": "2023-11-29T08:16:14.481896Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weight_label\n",
       "2    60\n",
       "1    60\n",
       "3    40\n",
       "0    20\n",
       "4    10\n",
       "6     5\n",
       "5     5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "]\n",
    "# weights = {int(k):v for k,v in enumerate(weights)}\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "weight_label = pd.Series(le.fit_transform(weights), name='weight_label')\n",
    "weight_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:16:14.490138Z",
     "iopub.status.busy": "2023-11-29T08:16:14.490031Z",
     "iopub.status.idle": "2023-11-29T08:16:14.643401Z",
     "shell.execute_reply": "2023-11-29T08:16:14.642834Z",
     "shell.execute_reply.started": "2023-11-29T08:16:14.490128Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df.copy()\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:16:14.644194Z",
     "iopub.status.busy": "2023-11-29T08:16:14.644021Z",
     "iopub.status.idle": "2023-11-29T08:19:35.529036Z",
     "shell.execute_reply": "2023-11-29T08:19:35.528340Z",
     "shell.execute_reply.started": "2023-11-29T08:16:14.644182Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_4</th>\n",
       "      <th>top_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>137</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>153</td>\n",
       "      <td>70</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>79</td>\n",
       "      <td>37</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>137</td>\n",
       "      <td>131</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>148</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>137</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>137</td>\n",
       "      <td>9</td>\n",
       "      <td>131</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          top_1  top_2  top_3  top_4  top_5\n",
       "stock_id                                   \n",
       "0             0     37    110      2     66\n",
       "1             1     79    137     37      3\n",
       "2             2    142    153     70    174\n",
       "3             3    137     79     37    109\n",
       "4             4      9    137    131     99\n",
       "...         ...    ...    ...    ...    ...\n",
       "195         195    148     37      3    123\n",
       "196         196    137     79      3     37\n",
       "197         197    137      9    131     99\n",
       "198         198     12      5     15    115\n",
       "199         199     15     49     52    115\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'time_id'\n",
      "'time_id'\n",
      "'time_id'\n",
      "'time_id'\n",
      "'time_id'\n",
      "'time_id'\n",
      "'time_id'\n",
      "'time_id'\n",
      "Feature length = 166\n"
     ]
    }
   ],
   "source": [
    "global_stock_id_feats = {\n",
    "    \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median() + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
    "    \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std() + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
    "    \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max() - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
    "    \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median() + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
    "    \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std() + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
    "    \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max() - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n",
    "}\n",
    "\n",
    "df_train = pd.merge(df_train, weight_label, left_on='stock_id', right_index=True)\n",
    "global_weight_feats = {\n",
    "    \"median_size\": df_train.groupby(\"weight_label\")[\"bid_size\"].median() + df_train.groupby(\"weight_label\")[\"ask_size\"].median(),\n",
    "    \"std_size\": df_train.groupby(\"weight_label\")[\"bid_size\"].std() + df_train.groupby(\"weight_label\")[\"ask_size\"].std(),\n",
    "    \"ptp_size\": df_train.groupby(\"weight_label\")[\"bid_size\"].max() - df_train.groupby(\"weight_label\")[\"bid_size\"].min(),\n",
    "    \"median_price\": df_train.groupby(\"weight_label\")[\"bid_price\"].median() + df_train.groupby(\"weight_label\")[\"ask_price\"].median(),\n",
    "    \"std_price\": df_train.groupby(\"weight_label\")[\"bid_price\"].std() + df_train.groupby(\"weight_label\")[\"ask_price\"].std(),\n",
    "    \"ptp_price\": df_train.groupby(\"weight_label\")[\"bid_price\"].max() - df_train.groupby(\"weight_label\")[\"ask_price\"].min(),\n",
    "}\n",
    "if CFG.TRAINING:\n",
    "    df_train_feats = generate_all_features(df_train)\n",
    "    df_train_feats = reduce_mem_usage(df_train_feats)\n",
    "\n",
    "    feature_name = list(df_train_feats.columns)\n",
    "    print(f'Feature length = {len(feature_name)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:27:19.713127Z",
     "iopub.status.busy": "2023-11-29T08:27:19.712926Z",
     "iopub.status.idle": "2023-11-29T08:27:19.716593Z",
     "shell.execute_reply": "2023-11-29T08:27:19.715778Z",
     "shell.execute_reply.started": "2023-11-29T08:27:19.713113Z"
    }
   },
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_columns', 200):\n",
    "#     display(\n",
    "#         pd.concat(\n",
    "#             [df_train_feats[df_train_feats['stock_id'] == 0].head(15),\n",
    "#             df_train_feats[df_train_feats['stock_id'] == 0].tail(5)]\n",
    "#         )\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:27:19.937495Z",
     "iopub.status.busy": "2023-11-29T08:27:19.936993Z",
     "iopub.status.idle": "2023-11-29T08:27:19.940592Z",
     "shell.execute_reply": "2023-11-29T08:27:19.939797Z",
     "shell.execute_reply.started": "2023-11-29T08:27:19.937473Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train_feats.columns[df_train_feats.head(1000).T.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-29T08:27:20.871965Z",
     "iopub.status.busy": "2023-11-29T08:27:20.871372Z",
     "iopub.status.idle": "2023-11-29T08:27:37.319482Z",
     "shell.execute_reply": "2023-11-29T08:27:37.318802Z",
     "shell.execute_reply.started": "2023-11-29T08:27:20.871941Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature length = 166\n",
      "Cluster 2\n",
      "Fold 1 Model Training\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 66\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Train a LightGBM model for the current fold\u001b[39;00m\n\u001b[1;32m     65\u001b[0m lgb_model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlgb_params)\n\u001b[0;32m---> 66\u001b[0m \u001b[43mlgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_fold_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_fold_train_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_fold_valid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_fold_valid_target\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m models\u001b[38;5;241m.\u001b[39mappend(lgb_model)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Save the model to a file\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:895\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y,\n\u001b[1;32m    889\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    890\u001b[0m         eval_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    891\u001b[0m         eval_init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    892\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    893\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    894\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 895\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    745\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    746\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    285\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    286\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    288\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    289\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    290\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 292\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m evaluation_result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3021\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import gc\n",
    "\n",
    "if CFG.TRAINING and 'LGBM' in CFG.methods:\n",
    "    lgb_params = {\n",
    "        \"objective\": \"mae\",\n",
    "        \"n_estimators\": 6000 if not CFG.is_test_mode else 500,\n",
    "        \"num_leaves\": 256,\n",
    "        \"subsample\": 0.6,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"learning_rate\": 0.00871,\n",
    "        'max_depth': 11,\n",
    "        \"n_jobs\": 4,\n",
    "        \"device\": 'gpu' if CFG.is_gpu else 'cpu',\n",
    "        \"verbosity\": -1,\n",
    "        \"importance_type\": \"gain\",\n",
    "        'seed': CFG.state,\n",
    "    }\n",
    "    feature_name = list(df_train_feats.columns)\n",
    "    print(f\"Feature length = {len(feature_name)}\")\n",
    "    \n",
    "    num_folds = 5\n",
    "    fold_size = 480 // num_folds\n",
    "    gap = 5\n",
    "    \n",
    "    lgb_models = {}\n",
    "    scores = {}\n",
    "    \n",
    "    model_save_path = f'{CFG.model_path}lgb_model' \n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.makedirs(model_save_path)\n",
    "    \n",
    "    for cluster in df_train_feats['weight_label'].unique():\n",
    "        print(f'Cluster {cluster}')\n",
    "        cluster_train = df_train_feats[df_train_feats['weight_label'] == cluster]\n",
    "        cluster_train_target = df_train['target'][df_train['weight_label'] == cluster]\n",
    "\n",
    "        date_ids = df_train.loc[df_train['weight_label'] == cluster, 'date_id'].values\n",
    "        \n",
    "        for i in range(num_folds):\n",
    "            start = i * fold_size\n",
    "            end = start + fold_size\n",
    "            if i < num_folds - 1:  # No need to purge after the last fold\n",
    "                purged_start = end - 2\n",
    "                purged_end = end + gap + 2\n",
    "                train_indices = (date_ids >= start) & (date_ids < purged_start) | (date_ids > purged_end)\n",
    "            else:\n",
    "                train_indices = (date_ids >= start) & (date_ids < end)\n",
    "            \n",
    "            test_indices = (date_ids >= end) & (date_ids < end + fold_size)\n",
    "            \n",
    "            df_fold_train = cluster_train[train_indices]\n",
    "            df_fold_train_target = cluster_train_target[train_indices]\n",
    "            df_fold_valid = cluster_train[test_indices]\n",
    "            df_fold_valid_target = cluster_train_target[test_indices]\n",
    "        \n",
    "            print(f\"Fold {i+1} Model Training\")\n",
    "    \n",
    "            models = []\n",
    "            tmp_scores = []\n",
    "\n",
    "            # Train a LightGBM model for the current fold\n",
    "            lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "            lgb_model.fit(\n",
    "                df_fold_train[feature_name],\n",
    "                df_fold_train_target,\n",
    "                eval_set=[(df_fold_valid[feature_name], df_fold_valid_target)],\n",
    "                callbacks=[\n",
    "                    lgb.callback.early_stopping(stopping_rounds=100),\n",
    "                    lgb.callback.log_evaluation(period=100),\n",
    "                ],\n",
    "            )\n",
    "        \n",
    "            models.append(lgb_model)\n",
    "            # Save the model to a file\n",
    "            model_filename = os.path.join(model_save_path, f'lgb_cluster{cluster}_cv{i+1}.txt')\n",
    "            lgb_model.booster_.save_model(model_filename, importance_type='gain')\n",
    "            print(f\"Model for fold {i+1} cluster {cluster} saved to {model_filename}\")\n",
    "        \n",
    "            # Evaluate model performance on the validation set\n",
    "            fold_predictions = lgb_model.predict(df_fold_valid[feature_name])\n",
    "            fold_score = mean_absolute_error(fold_predictions, df_fold_valid_target)\n",
    "            tmp_scores.append(fold_score)\n",
    "            print(f\"Fold {i+1} Cluster {cluster} MAE: {fold_score}\")\n",
    "\n",
    "        # Free up memory by deleting fold specific variables\n",
    "        # del df_fold_train, df_fold_train_target, df_fold_valid, df_fold_valid_target\n",
    "        # gc.collect()\n",
    "    \n",
    "        # Calculate the average best iteration from all regular folds\n",
    "        average_best_iteration = int(np.mean([model.best_iteration_ for model in models]))\n",
    "        \n",
    "        # Update the lgb_params with the average best iteration\n",
    "        final_model_params = lgb_params.copy()\n",
    "        final_model_params['n_estimators'] = average_best_iteration\n",
    "        \n",
    "        print(f\"Cluster{cluster} Training final model with average best iteration: {average_best_iteration}\")\n",
    "        \n",
    "        # Train the final model on the entire dataset\n",
    "        final_model = lgb.LGBMRegressor(**final_model_params)\n",
    "        final_model.fit(\n",
    "            cluster_train[feature_name],\n",
    "            cluster_train_target,\n",
    "            callbacks=[\n",
    "                lgb.callback.log_evaluation(period=100),\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        # Append the final model to the list of models\n",
    "        models.append(final_model)\n",
    "        lgb_models[f'Cluster{i}'] = models\n",
    "        scores[f'Cluster{i}'] = tmp_scores\n",
    "        \n",
    "        # Save the final model to a file\n",
    "        final_model_filename = os.path.join(model_save_path, f'lgb_cluster{cluster}_fin.txt')\n",
    "        final_model.booster_.save_model(final_model_filename, importance_type='gain')\n",
    "        print(f\"Final model saved to {final_model_filename}\")\n",
    "        \n",
    "        # Now 'models' holds the trained models for each fold and 'scores' holds the validation scores\n",
    "        print(f\"Average MAE across all folds: {np.mean(tmp_scores)}\")\n",
    "    \n",
    "    # os.makedirs(f'{model_save_path}/scores', exist_ok=True)\n",
    "    # scores.insert(0, lgb_params)\n",
    "    # scores.insert(1, len(feature_name))\n",
    "    # scores.insert(2, feature_name)\n",
    "    # with open(f'{model_save_path}/scores/lgbm{datetime.datetime.now()}_{len(feature_name)}.txt', 'w') as f:\n",
    "    #     print(*scores, file=f, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T13:49:05.450735Z",
     "iopub.status.busy": "2023-11-22T13:49:05.450491Z",
     "iopub.status.idle": "2023-11-22T13:49:05.464843Z",
     "shell.execute_reply": "2023-11-22T13:49:05.464192Z",
     "shell.execute_reply.started": "2023-11-22T13:49:05.450712Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if CFG.TRAINING and 'CBT' in CFG.methods:\n",
    "    cbt_params = {\n",
    "        'task_type'           : 'GPU' if CFG.is_gpu else 'CPU',\n",
    "        'objective'           : 'MAE',\n",
    "        'eval_metric'         : 'MAE',\n",
    "        'bagging_temperature' : 0.5,\n",
    "    #     'colsample_bylevel'   : 0.7,\n",
    "        'iterations'          : 500 if not CFG.is_test_mode else 100,\n",
    "        'early_stopping_rounds' : 50 if not CFG.is_test_mode else 10,\n",
    "        'learning_rate'       : 0.065,\n",
    "        'max_depth'           : 7,\n",
    "        'l2_leaf_reg'         : 1.5,\n",
    "        'min_data_in_leaf'    : 1000,\n",
    "        'random_strength'     : 0.65, \n",
    "        'verbose'             : 0,\n",
    "        'use_best_model'      : True,\n",
    "        'random_seed'         : CFG.state,\n",
    "    }\n",
    "    feature_name = list(df_train_feats.columns)\n",
    "    print(f\"Feature length = {len(feature_name)}\")\n",
    "    \n",
    "    num_folds = 5\n",
    "    fold_size = 480 // num_folds\n",
    "    gap = 5\n",
    "    \n",
    "    cbt_models = []\n",
    "    scores = []\n",
    "    \n",
    "    model_save_path = f'{CFG.model_path}cbt_model' \n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.makedirs(model_save_path)\n",
    "    \n",
    "    date_ids = df_train['date_id'].values\n",
    "    \n",
    "    for i in range(num_folds):\n",
    "        start = i * fold_size\n",
    "        end = start + fold_size\n",
    "        if i < num_folds - 1:  # No need to purge after the last fold\n",
    "            purged_start = end - 2\n",
    "            purged_end = end + gap + 2\n",
    "            train_indices = (date_ids >= start) & (date_ids < purged_start) | (date_ids > purged_end)\n",
    "        else:\n",
    "            train_indices = (date_ids >= start) & (date_ids < end)\n",
    "        \n",
    "        test_indices = (date_ids >= end) & (date_ids < end + fold_size)\n",
    "        \n",
    "        df_fold_train = df_train_feats[train_indices]\n",
    "        df_fold_train_target = df_train['target'][train_indices]\n",
    "        df_fold_valid = df_train_feats[test_indices]\n",
    "        df_fold_valid_target = df_train['target'][test_indices]\n",
    "        cbt_train = cbt.Pool(df_fold_train, df_fold_train_target)\n",
    "        cbt_valid = cbt.Pool(df_fold_valid, df_fold_valid_target)\n",
    "    \n",
    "        print(f\"Fold {i+1} Model Training\")\n",
    "        \n",
    "        # Train a LightGBM model for the current fold\n",
    "        cbt_model = cbt.CatBoostRegressor(**cbt_params)\n",
    "        cbt_model.fit(\n",
    "            cbt_train,\n",
    "            eval_set=[cbt_valid],\n",
    "        )\n",
    "    \n",
    "        cbt_models.append(cbt_model)\n",
    "        # Save the model to a file\n",
    "        model_filename = os.path.join(model_save_path, f'cbt_cv{i+1}.cbm')\n",
    "        cbt_model.save_model(model_filename)\n",
    "        print(f\"Model for fold {i+1} saved to {model_filename}\")\n",
    "    \n",
    "        # Evaluate model performance on the validation set\n",
    "        fold_predictions = cbt_model.predict(df_fold_valid[feature_name])\n",
    "        fold_score = mean_absolute_error(fold_predictions, df_fold_valid_target)\n",
    "        scores.append(fold_score)\n",
    "        print(f\"Fold {i+1} MAE: {fold_score}\")\n",
    "    \n",
    "        # Free up memory by deleting fold specific variables\n",
    "        del df_fold_train, df_fold_train_target, df_fold_valid, df_fold_valid_target\n",
    "        gc.collect()\n",
    "    \n",
    "    # Calculate the average best iteration from all regular folds\n",
    "    average_best_iteration = int(np.mean([model.get_best_iteration() for model in cbt_models]))\n",
    "    \n",
    "    # Update the lgb_params with the average best iteration\n",
    "    final_model_params = cbt_params.copy()\n",
    "    final_model_params['iterations'] = average_best_iteration\n",
    "    final_model_params['use_best_model'] = False\n",
    "    \n",
    "    print(f\"Training final model with average best iteration: {average_best_iteration}\")\n",
    "    \n",
    "    # Train the final model on the entire dataset\n",
    "    final_model = cbt.CatBoostRegressor(**final_model_params)\n",
    "    final_model.fit(\n",
    "        df_train_feats[feature_name],\n",
    "        df_train['target'],\n",
    "    )\n",
    "    \n",
    "    # Append the final model to the list of models\n",
    "    cbt_models.append(final_model)\n",
    "    \n",
    "    # Save the final model to a file\n",
    "    final_model_filename = os.path.join(model_save_path, 'cbt_fin.cbm')\n",
    "    final_model.save_model(final_model_filename)\n",
    "    print(f\"Final model saved to {final_model_filename}\")\n",
    "    \n",
    "    # Now 'models' holds the trained models for each fold and 'scores' holds the validation scores\n",
    "    print(f\"Average MAE across all folds: {np.mean(scores)}\")\n",
    "\n",
    "    os.makedirs(f'{model_save_path}/scores', exist_ok=True)\n",
    "    scores.insert(0, cbt_params)\n",
    "    scores.insert(1, len(feature_name))\n",
    "    scores.insert(2, feature_name)\n",
    "    np.savetxt(f'{model_save_path}/scores/cbt{datetime.datetime.now()}_{len(feature_name)}.txt', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T13:49:05.466220Z",
     "iopub.status.busy": "2023-11-22T13:49:05.465747Z",
     "iopub.status.idle": "2023-11-22T13:49:05.484389Z",
     "shell.execute_reply": "2023-11-22T13:49:05.483738Z",
     "shell.execute_reply.started": "2023-11-22T13:49:05.466196Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "if CFG.TRAINING and 'XGB' in CFG.methods:\n",
    "    params = {\n",
    "        'task_type'           : 'GPU' if CFG.is_gpu else 'CPU',\n",
    "        'objective'           : 'MAE',\n",
    "        'eval_metric'         : 'MAE',\n",
    "        'bagging_temperature' : 0.5,\n",
    "    #     'colsample_bylevel'   : 0.7,\n",
    "        'iterations'          : 500 if not CFG.is_test_mode else 100,\n",
    "        'early_stopping_rounds' : 50 if not CFG.is_test_mode else 10,\n",
    "        'learning_rate'       : 0.065,\n",
    "        'max_depth'           : 7,\n",
    "        'l2_leaf_reg'         : 1.5,\n",
    "        'min_data_in_leaf'    : 1000,\n",
    "        'random_strength'     : 0.65, \n",
    "        'verbose'             : 0,\n",
    "        'use_best_model'      : True,\n",
    "        'random_seed'         : CFG.state,\n",
    "    }\n",
    "    feature_name = list(df_train_feats.columns)\n",
    "    print(f\"Feature length = {len(feature_name)}\")\n",
    "    \n",
    "    num_folds = 5\n",
    "    fold_size = 480 // num_folds\n",
    "    gap = 5\n",
    "    \n",
    "    xgb_models = []\n",
    "    scores = []\n",
    "    \n",
    "    model_save_path = f'{CFG.model_path}xgb_model' \n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.makedirs(model_save_path)\n",
    "    \n",
    "    date_ids = df_train['date_id'].values\n",
    "    \n",
    "    for i in range(num_folds):\n",
    "        start = i * fold_size\n",
    "        end = start + fold_size\n",
    "        if i < num_folds - 1:  # No need to purge after the last fold\n",
    "            purged_start = end - 2\n",
    "            purged_end = end + gap + 2\n",
    "            train_indices = (date_ids >= start) & (date_ids < purged_start) | (date_ids > purged_end)\n",
    "        else:\n",
    "            train_indices = (date_ids >= start) & (date_ids < end)\n",
    "        \n",
    "        test_indices = (date_ids >= end) & (date_ids < end + fold_size)\n",
    "        \n",
    "        df_fold_train = df_train_feats[train_indices]\n",
    "        df_fold_train_target = df_train['target'][train_indices]\n",
    "        df_fold_valid = df_train_feats[test_indices]\n",
    "        df_fold_valid_target = df_train['target'][test_indices]\n",
    "    \n",
    "        print(f\"Fold {i+1} Model Training\")\n",
    "        \n",
    "        # Train a LightGBM model for the current fold\n",
    "        model = xgb.XGBoostRegressor(**params)\n",
    "        model.fit(\n",
    "        )\n",
    "        \n",
    "        xgb_models.append(model)\n",
    "        # Save the model to a file\n",
    "        model_filename = os.path.join(model_save_path, f'xgb_cv{i+1}.txt')\n",
    "        model.save_model(model_filename)\n",
    "        print(f\"Model for fold {i+1} saved to {model_filename}\")\n",
    "    \n",
    "        # Evaluate model performance on the validation set\n",
    "        fold_predictions = model.predict(df_fold_valid[feature_name])\n",
    "        fold_score = mean_absolute_error(fold_predictions, df_fold_valid_target)\n",
    "        scores.append(fold_score)\n",
    "        print(f\"Fold {i+1} MAE: {fold_score}\")\n",
    "    \n",
    "        # Free up memory by deleting fold specific variables\n",
    "        del df_fold_train, df_fold_train_target, df_fold_valid, df_fold_valid_target\n",
    "        gc.collect()\n",
    "    \n",
    "    # Calculate the average best iteration from all regular folds\n",
    "    average_best_iteration = int(np.mean([model.get_best_iteration() for model in xgb_models]))\n",
    "    \n",
    "    # Update the lgb_params with the average best iteration\n",
    "    final_model_params = params.copy()\n",
    "    final_model_params['iterations'] = average_best_iteration\n",
    "    final_model_params['use_best_model'] = False\n",
    "    \n",
    "    print(f\"Training final model with average best iteration: {average_best_iteration}\")\n",
    "    \n",
    "    # Train the final model on the entire dataset\n",
    "    final_model = xgb.XGBoostRegressor(**final_model_params)\n",
    "    final_model.fit(\n",
    "        df_train_feats[feature_name],\n",
    "        df_train['target'],\n",
    "    )\n",
    "    \n",
    "    # Append the final model to the list of models\n",
    "    xgb_models.append(final_model)\n",
    "    \n",
    "    # Save the final model to a file\n",
    "    final_model_filename = os.path.join(model_save_path, 'xgb_fin.cbm')\n",
    "    final_model.save_model(final_model_filename)\n",
    "    print(f\"Final model saved to {final_model_filename}\")\n",
    "    \n",
    "    # Now 'models' holds the trained models for each fold and 'scores' holds the validation scores\n",
    "    print(f\"Average MAE across all folds: {np.mean(scores)}\")\n",
    "\n",
    "    os.makedirs(f'{model_save_path}/scores', exist_ok=True)\n",
    "    scores.insert(0, params)\n",
    "    scores.insert(1, len(feature_name))\n",
    "    scores.insert(2, feature_name)\n",
    "    np.savetxt(f'{model_save_path}/scores/xgb{datetime.datetime.now()}_{len(feature_name)}.txt', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T13:49:05.488221Z",
     "iopub.status.busy": "2023-11-22T13:49:05.487770Z",
     "iopub.status.idle": "2023-11-22T13:49:05.500719Z",
     "shell.execute_reply": "2023-11-22T13:49:05.500054Z",
     "shell.execute_reply.started": "2023-11-22T13:49:05.488199Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices) / np.sum(std_error)\n",
    "    out = prices - std_error * step\n",
    "    return out\n",
    "\n",
    "if CFG.INFERENCE:\n",
    "    import optiver2023\n",
    "    env = optiver2023.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    counter = 0\n",
    "    y_min, y_max = -64, 64\n",
    "    qps, predictions = [], []\n",
    "    cache = pd.DataFrame()\n",
    "    \n",
    "    lgb_models = [\n",
    "#         lgb.Booster(model_file='/kaggle/input/optiver-lgbm/lgb_model/lgb_cv1.txt'),\n",
    "#         lgb.Booster(model_file='/kaggle/input/optiver-lgbm/lgb_model/lgb_cv2.txt'),\n",
    "        lgb.Booster(model_file='/kaggle/input/optiver-lgbm/lgb_model/lgb_cv3.txt'),\n",
    "        lgb.Booster(model_file='/kaggle/input/optiver-lgbm/lgb_model/lgb_cv4.txt'),\n",
    "        lgb.Booster(model_file='/kaggle/input/optiver-lgbm/lgb_model/lgb_cv5.txt'),\n",
    "        lgb.Booster(model_file='/kaggle/input/optiver-lgbm/lgb_model/lgb_fin.txt'),\n",
    "    ]\n",
    "    cbt_models = [\n",
    "#         cbt.CatBoostRegressor().load_model('/kaggle/input/optiver-catboost/cbt_model/cbt_cv1.cbm'),\n",
    "#         cbt.CatBoostRegressor().load_model('/kaggle/input/optiver-catboost/cbt_model/cbt_cv2.cbm'),\n",
    "#         cbt.CatBoostRegressor().load_model('/kaggle/input/optiver-catboost/cbt_model/cbt_cv3.cbm'),\n",
    "#         cbt.CatBoostRegressor().load_model('/kaggle/input/optiver-catboost/cbt_model/cbt_cv4.cbm'),\n",
    "        cbt.CatBoostRegressor().load_model('/kaggle/input/optiver-catboost/cbt_model/cbt_cv5.cbm'),\n",
    "        cbt.CatBoostRegressor().load_model('/kaggle/input/optiver-catboost/cbt_model/cbt_fin.cbm'),\n",
    "    ]\n",
    "    # Weights for each fold model\n",
    "    lgb_model_weights = [0.1, 0.2, 0.3, 0.4]\n",
    "    cbt_model_weights = [0.4, 0.6]\n",
    "#     lgb_model_weights = [1/len(lgb_models)] * len(lgb_models)\n",
    "#     cbt_model_weights = [1/len(cbt_models)] * len(cbt_models)\n",
    "    \n",
    "    for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "        now_time = time.time()\n",
    "        cache = pd.concat([cache, test], ignore_index=True, axis=0)\n",
    "        if counter > 0:\n",
    "            cache = cache.groupby(['stock_id']).tail(21).sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id']).reset_index(drop=True)\n",
    "        feat = generate_all_features(cache)[-len(test):]\n",
    "\n",
    "        if test.currently_scored.iloc[0] == False:\n",
    "            sample_prediction['target'] = 0\n",
    "            env.predict(sample_prediction)\n",
    "            counter += 1\n",
    "            qps.append(time.time() - now_time)\n",
    "            if counter % 10 == 0:\n",
    "                print(counter, 'qps:', np.mean(qps))\n",
    "            continue\n",
    "                    \n",
    "        feat = feat.drop(columns=['currently_scored'])\n",
    "\n",
    "        # Generate predictions for each model and calculate the weighted average\n",
    "        lgb_predictions = np.zeros(len(test))\n",
    "        for model, weight in zip(lgb_models, lgb_model_weights):\n",
    "            lgb_predictions += weight * model.predict(feat)\n",
    "\n",
    "        lgb_predictions = zero_sum(lgb_predictions, test['bid_size']+test['ask_size'])\n",
    "        clipped_predictions = np.clip(lgb_predictions, y_min, y_max)\n",
    "        sample_prediction['target'] = clipped_predictions\n",
    "        # CatBoost\n",
    "        cbt_predictions = np.zeros(len(test))\n",
    "        for model, weight in zip(cbt_models, cbt_model_weights):\n",
    "            cbt_predictions += weight * model.predict(feat)\n",
    "\n",
    "        cbt_predictions = zero_sum(cbt_predictions, test['bid_size']+test['ask_size'])\n",
    "        clipped_predictions = np.clip(cbt_predictions, y_min, y_max)\n",
    "        sample_prediction['target'] = 0.4 * clipped_predictions + 0.6 * sample_prediction['target']\n",
    "\n",
    "        env.predict(sample_prediction)\n",
    "        counter += 1\n",
    "        qps.append(time.time() - now_time)\n",
    "        if counter % 10 == 0:\n",
    "            print(counter, 'qps:', np.mean(qps))\n",
    "\n",
    "    time_cost = 1.146 * np.mean(qps)\n",
    "    print(f\"The code will take approximately {np.round(time_cost, 4)} hours to reason about\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
