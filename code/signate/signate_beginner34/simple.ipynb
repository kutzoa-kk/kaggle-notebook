{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c6e19-3147-4823-8f73-4b52d921b335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoost\n",
    "from catboost import Pool\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a821894-8c9f-45e2-a04b-27815ff4ebec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/dataset/signate_beginner34/train.csv')\n",
    "df_test = pd.read_csv('/dataset/signate_beginner34/test.csv')\n",
    "sample_submission = pd.read_csv('/dataset/signate_beginner34/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e903415-912c-45e0-a8e6-b1be9b7e6c69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f94ff2-58aa-42e3-baa2-9c014c92e097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    data = df.copy()\n",
    "    data['sc_size'] = data['sc_h'] * data['sc_w']\n",
    "    data['spec'] = data['clock_speed'] * data['n_cores']\n",
    "\n",
    "    feature = ['int_memory', 'm_dep', 'mobile_wt',\n",
    "               'pc', 'px_height', 'px_width', 'ram',\n",
    "               'spec']\n",
    "    return data[feature]\n",
    "\n",
    "def f1(y_pred, train_data):\n",
    "    N_LABELS = 4\n",
    "    reshaped_preds = y_pred.reshape(N_LABELS, len(y_pred) // N_LABELS)\n",
    "    y_pred_ = reshaped_preds.argmax(axis=0)\n",
    "    y_true = train_data.get_label()\n",
    "    score = f1_score(y_true, y_pred_, average='macro')\n",
    "    return 'f1', score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55396613-06cf-4b38-b7a2-a0e248c35530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = preprocessing(df_train)\n",
    "y = df_train['price_range']\n",
    "\n",
    "# 学習データとテストデータに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "# 学習データを学習用と検証用に分割\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=42,\n",
    "                                                      stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc761e-d87a-4e97-8563-b62cf700fa2a",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142db724-92dc-4df8-ae47-3c8398969b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class XGBoost:\n",
    "    def __init__(self,\n",
    "                 X_train, y_train,\n",
    "                 X_valid, y_valid,\n",
    "                 X_test, y_test):\n",
    "        # 学習用\n",
    "        self.train_data = xgb.DMatrix(X_train, label=y_train)\n",
    "        # 検証用\n",
    "        self.valid_data = xgb.DMatrix(X_valid, label=y_valid)\n",
    "        # テスト用\n",
    "        self.test_data = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    def train(self, params=None):\n",
    "        # パラメータを設定\n",
    "        if params is None:\n",
    "            self.params = {\n",
    "                'objective': 'multi:softprob',  # 多値分類問題\n",
    "                'num_class': 4,                 # 目的変数のクラス数\n",
    "                'learning_rate': 0.01,           # 学習率\n",
    "                'eval_metric': 'mlogloss'       # 学習用の指標 (Multiclass logloss)\n",
    "            }\n",
    "        else:\n",
    "            self.params = params\n",
    "\n",
    "        # 学習\n",
    "        evals = [(self.train_data, 'train'), (self.valid_data, 'eval')]  # 学習に用いる検証用データ\n",
    "        evaluation_results = {}                            # 学習の経過を保存する箱\n",
    "        bst = xgb.train(self.params,                       # 上記で設定したパラメータ\n",
    "                        self.train_data,                    # 使用するデータセット\n",
    "                        num_boost_round=20000,             # 学習の回数\n",
    "                        early_stopping_rounds=100,         # アーリーストッピング\n",
    "                        evals=evals,                       # 学習経過で表示する名称\n",
    "                        evals_result=evaluation_results,   # 上記で設定した検証用データ\n",
    "                        verbose_eval=0                     # 学習の経過の表示(非表示)\n",
    "                        )\n",
    "\n",
    "        # テストデータで予測\n",
    "        y_pred = bst.predict(self.test_data)\n",
    "        y_pred_max = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(self.test_data.get_label(), y_pred_max)\n",
    "        print('XGBoost Accuracy:', accuracy)\n",
    "\n",
    "        return (bst, y_pred_max, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac2ecf-e7f8-44d3-bd8f-4a12d3c758ec",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13148b7c-6cf1-4547-9136-f6df11e25840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LightGBM:\n",
    "    def __init__(self,\n",
    "                 X_train, y_train,\n",
    "                 X_valid, y_valid,\n",
    "                 X_test, y_test):\n",
    "        # 学習用\n",
    "        self.train_data = lgb.Dataset(X_train, y_train,\n",
    "                                      free_raw_data=False)\n",
    "        # 検証用\n",
    "        self.valid_data = lgb.Dataset(X_valid, y_valid,\n",
    "                                      reference=self.train_data,\n",
    "                                      free_raw_data=False)\n",
    "        self.test_data = lgb.Dataset(X_test, y_test, free_raw_data=False).construct()\n",
    "\n",
    "    def train(self, params=None):\n",
    "        # パラメータを設定\n",
    "        if params is None:\n",
    "            self.params = {\n",
    "                'task': 'train',                # レーニング ⇔　予測predict\n",
    "                'boosting_type': 'gbdt',        # 勾配ブースティング\n",
    "                'objective': 'multiclass',      # 目的関数：多値分類、マルチクラス分類\n",
    "                'metric': 'multi_logloss',      # 検証用データセットで、分類モデルの性能を測る指標\n",
    "                'num_class': 4,                 # 目的変数のクラス数\n",
    "                'learning_rate': 0.01,           # 学習率（初期値0.1）\n",
    "                'num_leaves': 23,               # 決定木の複雑度を調整（初期値31）\n",
    "                'min_data_in_leaf': 1,          # データの最小数（初期値20）\n",
    "                'verbosity': -1\n",
    "            }\n",
    "        else:\n",
    "            self.params = params\n",
    "\n",
    "        # 学習\n",
    "        evaluation_results = {}                                # 学習の経過を保存する箱\n",
    "        model = lgb.train(self.params,                              # 上記で設定したパラメータ\n",
    "                          self.train_data,                      # 使用するデータセット\n",
    "                          num_boost_round=20000,               # 学習の回数\n",
    "                          valid_names=['train', 'valid'],      # 学習経過で表示する名称\n",
    "                          valid_sets=[self.train_data, self.valid_data],    # モデルの検証に使用するデータセット\n",
    "                          callbacks=[\n",
    "                              lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
    "                              lgb.log_evaluation(0),            # この数字を1にすると学習時のスコア推移がコマンドライン表示される\n",
    "                              lgb.record_evaluation(evaluation_results),\n",
    "                          ])\n",
    "\n",
    "        # テストデータで予測\n",
    "        y_pred = model.predict(self.test_data.get_data(), num_iteration=model.best_iteration)\n",
    "        y_pred_max = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # Accuracy の計算\n",
    "        accuracy = sum(self.test_data.get_label() == y_pred_max) / len(self.test_data.get_label())\n",
    "        print('LightGBM Accuracy:', accuracy)\n",
    "\n",
    "        return(model, y_pred_max, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc28566f-a493-4f20-b50f-2ae32b1a9dd5",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66161e47-2a11-46ec-ae94-138f3889304d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CatBoostModel:\n",
    "    def __init__(self,\n",
    "                 X_train, y_train,\n",
    "                 X_valid, y_valid,\n",
    "                 X_test, y_test):\n",
    "        # 学習用\n",
    "        self.train_data = Pool(X_train, label=y_train)\n",
    "        # 検証用\n",
    "        self.valid_data = Pool(X_valid, label=y_valid)\n",
    "        self.test_data = Pool(X_test, y_test)\n",
    "\n",
    "    def train(self, params=None):\n",
    "        # パラメータを設定\n",
    "        if params is None:\n",
    "            self.params = {\n",
    "                'loss_function': 'MultiClass',    # 多値分類問題\n",
    "                'num_boost_round': 20000,          # 学習の回数\n",
    "                'early_stopping_rounds': 100       # アーリーストッピングの回数\n",
    "            }\n",
    "        else:\n",
    "            self.params = params\n",
    "\n",
    "        # 学習\n",
    "        catb = CatBoost(self.params)\n",
    "        catb.fit(self.train_data, eval_set=[self.valid_data], verbose=False)\n",
    "\n",
    "        # テストデータで予測\n",
    "        y_pred = catb.predict(self.test_data, prediction_type='Probability')\n",
    "        y_pred_max = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # Accuracy の計算\n",
    "        accuracy = sum(self.test_data.get_label() == y_pred_max) / len(self.test_data.get_label())\n",
    "        print('CatBoost Accuracy:', accuracy)\n",
    "\n",
    "        return (catb, y_pred_max, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b818ee4-040d-43f8-b312-bdff05770c6b",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd495d8-8220-427b-a871-0bdbea33ac46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'multi:softprob',  # 多値分類問題\n",
    "    'num_class': 4,                 # 目的変数のクラス数\n",
    "    'learning_rate': 0.01,           # 学習率\n",
    "    'eval_metric': 'mlogloss',       # 学習用の指標 (Multiclass logloss)\n",
    "}\n",
    "lgbm_params = {\n",
    "    'task': 'train',                # レーニング ⇔　予測predict\n",
    "    'boosting_type': 'gbdt',        # 勾配ブースティング\n",
    "    'objective': 'multiclass',      # 目的関数：多値分類、マルチクラス分類\n",
    "    'metric': 'multi_logloss',      # 検証用データセットで、分類モデルの性能を測る指標\n",
    "    'num_class': 4,                 # 目的変数のクラス数\n",
    "    'learning_rate': 0.01,           # 学習率（初期値0.1）\n",
    "    'num_leaves': 23,               # 決定木の複雑度を調整（初期値31）\n",
    "    'min_data_in_leaf': 1,          # データの最小数（初期値20）\n",
    "    'verbosity': -1\n",
    "}\n",
    "catb_params = {\n",
    "    'loss_function': 'MultiClass',    # 多値分類問題\n",
    "    'num_boost_round': 20000,          # 学習の回数\n",
    "    'early_stopping_rounds': 100       # アーリーストッピングの回数\n",
    "}\n",
    "\n",
    "# 各5つのモデルを保存するリストの初期化\n",
    "xgb_models = []\n",
    "lgbm_models = []\n",
    "catb_models = []\n",
    "# 各5つのモデルの正答率を保存するリストの初期化\n",
    "xgb_accuracies = []\n",
    "lgbm_accuracies = []\n",
    "catb_accuracies = []\n",
    "# 学習のカウンター\n",
    "loop_counts = 1\n",
    "\n",
    "loop_num = 5\n",
    "k_split_num = 5\n",
    "\n",
    "# 学習データとテストデータに分ける\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# 各5つのモデルの予測を保存する配列の初期化（5seed*5cv*3モデル）\n",
    "first_preds = np.zeros((len(y_test), loop_num * k_split_num * 3))\n",
    "\n",
    "\n",
    "# ５つのシード値で予測\n",
    "for seed_no in range(loop_num):\n",
    "    # 学習データの数だけの数列（0行から最終行まで連番）\n",
    "    row_no_list = list(range(len(y_train)))\n",
    "\n",
    "    # KFoldクラスをインスタンス化（これを使って5分割する）\n",
    "    K_fold = StratifiedKFold(n_splits=k_split_num, shuffle=True, random_state=seed_no)\n",
    "\n",
    "    # KFoldクラスで分割した回数だけ実行（ここでは5回）\n",
    "    for train_cv_no, eval_cv_no in K_fold.split(row_no_list, y_train):\n",
    "        print(f'===== Trail {loop_counts} =====')\n",
    "        # ilocで取り出す行を指定\n",
    "        X_train_cv = X_train.iloc[train_cv_no, :]\n",
    "        y_train_cv = pd.Series(y_train).iloc[train_cv_no]\n",
    "        X_eval_cv = X_train.iloc[eval_cv_no, :]\n",
    "        y_eval_cv = pd.Series(y_train).iloc[eval_cv_no]\n",
    "\n",
    "        # XGBoostの学習を実行\n",
    "        xgbc = XGBoost(X_train_cv, y_train_cv,\n",
    "                       X_eval_cv, y_eval_cv,\n",
    "                       X_test, y_test)\n",
    "        bst, bst_pred, bst_accuracy = xgbc.train(params=xgb_params)\n",
    "\n",
    "        # LightGBMの学習を実行\n",
    "        lgbc = LightGBM(X_train_cv, y_train_cv,\n",
    "                        X_eval_cv, y_eval_cv,\n",
    "                        X_test, y_test)\n",
    "        model, model_pred, model_accuracy = lgbc.train(params=lgbm_params)\n",
    "\n",
    "        # CatBoostの学習を実行\n",
    "        catc = CatBoostModel(X_train_cv, y_train_cv,\n",
    "                             X_eval_cv, y_eval_cv,\n",
    "                             X_test, y_test)\n",
    "        catb, catb_pred, catb_accuracy = catc.train(params=catb_params)\n",
    "\n",
    "        # 学習が終わったモデルをリストに入れておく\n",
    "        xgb_models.append(bst)\n",
    "        lgbm_models.append(model)\n",
    "        catb_models.append(catb)\n",
    "\n",
    "        # 学習が終わったモデルの正答率をリストに入れておく\n",
    "        xgb_accuracies.append(bst_accuracy)\n",
    "        lgbm_accuracies.append(model_accuracy)\n",
    "        catb_accuracies.append(catb_accuracy)\n",
    "\n",
    "        # 学習が終わったモデルの予測をリストに入れておく\n",
    "        first_preds[:, loop_counts-1] = bst_pred\n",
    "        first_preds[:, loop_counts-1 + 25] = model_pred\n",
    "        first_preds[:, loop_counts-1 + 50] = catb_pred\n",
    "\n",
    "        # 実行回数のカウント\n",
    "        loop_counts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58e197d-11f4-48db-a9e2-7daeb34583c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 単独のモデルでの、テストデータの正答率\n",
    "print('XGBoost Accuracy: ', np.array(xgb_accuracies).mean())\n",
    "print('LightGBM Accuracy: ', np.array(lgbm_accuracies).mean())\n",
    "print('CatBoost Accuracy: ', np.array(catb_accuracies).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b650a58a-e336-4ae8-8167-ac17af34734d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracies = [xgb_accuracies, lgbm_accuracies, catb_accuracies]\n",
    "# # 箱ひげ図の作成\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(accuracies, whis=3)\n",
    "plt.xticks(range(1, 4), ['XGBoost', 'LightGBM', 'CatBoost'])\n",
    "plt.title('Accuracy') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75900b79-7b98-4594-a3a7-f17055f4f6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# データ格納用のnumpy行列を作成\n",
    "first_preds_max = pd.DataFrame(np.zeros((len(y_test), 4)))\n",
    "\n",
    "# 予測したクラスのデータをpandas.DataFrameに入れる\n",
    "df_first_preds = pd.DataFrame(first_preds)\n",
    "\n",
    "# 各列（0,1,2）に、そのクラスを予測したモデルの数を入れる\n",
    "first_preds_max[first_preds_max.columns[0]] = (df_first_preds == 0).sum(axis=1)\n",
    "first_preds_max[first_preds_max.columns[1]] = (df_first_preds == 1).sum(axis=1)\n",
    "first_preds_max[first_preds_max.columns[2]] = (df_first_preds == 2).sum(axis=1)\n",
    "first_preds_max[first_preds_max.columns[3]] = (df_first_preds == 3).sum(axis=1)\n",
    "\n",
    "# 各行で、そのクラスを予測したモデルの数が最も多いクラスを得る\n",
    "pred_max = np.argmax(np.array(first_preds_max), axis=1)\n",
    "\n",
    "# Accuracy を計算する\n",
    "accuracy = sum(y_test == pred_max) / len(y_test)\n",
    "print('accuracy:', accuracy)\n",
    "\n",
    "df_accuracy = pd.DataFrame({'va_y': y_test,\n",
    "                            'y_pred_max': pred_max})\n",
    "print(pd.crosstab(df_accuracy['va_y'], df_accuracy['y_pred_max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb489959-4dd3-49ad-a035-0e5c0736fb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_data = preprocessing(df_test)\n",
    "xgb_test = xgb.DMatrix(X_test_data)\n",
    "lgb_test = lgb.Dataset(X_test_data)\n",
    "cat_test = Pool(X_test_data)\n",
    "\n",
    "preds = np.zeros((len(X_test_data), loop_num * k_split_num * 3))\n",
    "for index, (bst, lgbm, cat) in enumerate(zip(xgb_models, lgbm_models, catb_models)):\n",
    "    y_pred = bst.predict(xgb_test)\n",
    "    bst_pred = np.argmax(y_pred, axis=1)\n",
    "    y_pred = lgbm.predict(X_test_data, num_iteration=model.best_iteration)\n",
    "    lgb_pred = np.argmax(y_pred, axis=1)\n",
    "    y_pred = catb.predict(cat_test, prediction_type='Probability')\n",
    "    cat_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # 学習が終わったモデルの予測をリストに入れておく\n",
    "    preds[:, index] = bst_pred\n",
    "    preds[:, index + 25] = lgb_pred\n",
    "    preds[:, index + 50] = cat_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1788c06b-9014-42c9-9054-61927062950c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# データ格納用のnumpy行列を作成\n",
    "preds_max = pd.DataFrame(np.zeros((len(X_test_data), 4)))\n",
    "\n",
    "# 予測したクラスのデータをpandas.DataFrameに入れる\n",
    "df_preds = pd.DataFrame(preds)\n",
    "\n",
    "# 各列（0,1,2）に、そのクラスを予測したモデルの数を入れる\n",
    "preds_max[preds_max.columns[0]] = (df_preds == 0).sum(axis=1)\n",
    "preds_max[preds_max.columns[1]] = (df_preds == 1).sum(axis=1)\n",
    "preds_max[preds_max.columns[2]] = (df_preds == 2).sum(axis=1)\n",
    "preds_max[preds_max.columns[3]] = (df_preds == 3).sum(axis=1)\n",
    "\n",
    "pred_max = preds_max.idxmax(axis=1)\n",
    "pred_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca29000f-b419-4006-8ebf-c5c00ad3f405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.concat([df_test['id'], pred_max], axis=1)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f27c55-3847-41bc-9a84-98489ea47ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存\n",
    "save_folder = \"results\"\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "submission.to_csv(\"{}/submit_{}.csv\".format(save_folder, datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")),index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f131fb-8326-49c4-baf5-c1ea583e2fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = f1_score(y_test, y_pred_class, average='macro')\n",
    "# score\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# lgb.plot_importance(lgb_model)\n",
    "# plt.show()\n",
    "\n",
    "# score = f1_score(y_test, y_pred_class, average='macro')\n",
    "# score\n",
    "\n",
    "# xgb.plot_importance(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95a1e6-0bef-4e90-adb7-6b9696885bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# # クロスバリデーション用のScikit-Learnクラス（5分割KFold）\n",
    "# cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ###### ここからがLightGBMの実装 ######\n",
    "# # データをDatasetクラスに格納\n",
    "# dcv = lgb.Dataset(X, label=y)  # クロスバリデーション用\n",
    "# # 使用するパラメータ\n",
    "# params = {\n",
    "#     'objective': 'multiclass', # 多クラス分類\n",
    "#     'num_class': 4, # クラスの数\n",
    "#     'metric': 'multi_logloss', # 損失関数にmulti_loglossを使用\n",
    "#     'random_state': 42,  # 乱数シード\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'reg_alpha': 0.0,\n",
    "#     'reg_lambda': 0.0,\n",
    "#     'learning_rate':0.01, \n",
    "#     'drop_rate':0.5,\n",
    "#     'verbose': -1\n",
    "# }\n",
    "# verbose_eval = 0  # この数字を1にすると学習時のスコア推移がコマンドライン表示される\n",
    "# # early_stoppingを指定してLightGBMをクロスバリデーション\n",
    "# cv_result = lgb.cv(params, dcv,\n",
    "#                 num_boost_round=10000,  # 最大学習サイクル数。early_stopping使用時は大きな値を入力\n",
    "#                 folds=cv,\n",
    "#                 feval=f1,\n",
    "#                 callbacks=[lgb.early_stopping(stopping_rounds=100, \n",
    "#                                 verbose=True), # early_stopping用コールバック関数\n",
    "#                            lgb.log_evaluation(verbose_eval)] # コマンドライン出力用コールバック関数\n",
    "#                 )\n",
    "# # print(cv_result)\n",
    "# print(f'multi logloss mean={cv_result[\"multi_logloss-mean\"][-1]}')\n",
    "\n",
    "# test_data = preprocessing(df_test)\n",
    "# pred = ddmodel.predict(test_data)\n",
    "# pred_class = np.argmax(pred, axis=1)\n",
    "# pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6551bfdf-58e2-4054-9588-6f11c3f93b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = preprocessing(df_test)\n",
    "# pred = model.predict(test_data)\n",
    "# pred_class = np.argmax(pred, axis=1)\n",
    "\n",
    "emsemble_test = pd.DataFrame({\n",
    "    'XGB': np.argmax(xgb_model.predict(xgb.DMatrix(test_data)), axis=1),\n",
    "    'LGB': np.argmax(lgb_model.predict(test_data), axis=1)\n",
    "    })\n",
    "emsemble_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25257fdf-4b7a-4066-bc22-ee86d88d7e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean = emsemble_test['LGB'] * 0.8 + emsemble_test['XGB'] * 0.2\n",
    "pred_class = mean.round().astype(int)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249675f3-1d93-48dd-8ca9-04d905f290bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample_submission['2'] = proba\n",
    "submission = pd.concat([df_test['id'], pd.DataFrame(pred_class)], axis=1)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e1cedd-da52-4dc0-bbd7-b588d9135467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存\n",
    "save_folder = \"results\"\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "submission.to_csv(\"{}/submit_{}.csv\".format(save_folder, datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")),index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6275e320-e2e2-4356-ba41-23a5a350727b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
